{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 6 - Aplicação das Máquinas de Aprendizado Extremo (ELM)\n",
    "\n",
    "**Aluno:** Vítor Gabriel Reis Caitité\n",
    "\n",
    "**Matrícula:** $2021712430$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "O objetivo dos exercícios desta semana é utilizar as ELMs para resolver problemas multidimensionais, a partir de bases de dados reais.\n",
    "\n",
    "As bases de dados utilizadas pertencem ao repositório *UCI Machine Learning Repository* [1]. A primeira base de dados a ser estudada é a base Breast Cancer (diagnostic). Para esta base, os dados serão dividos de forma aleatória os dados entre treinamento e teste e comparar as acurácias de treinamento e teste para diferentes valores do hiperparâmetro que controla o número de neurônios. Os valores de acurácia serão apresentados na forma de *media +/- desvio padrão* para 10 execuções diferentes. O mesmo será feito para a base *Statlog (Heart)*.\n",
    "\n",
    "Além das Extreme Learning Machines, também será utilizado um modelo baseado no perceptron, e assim o desempenho na solução dos dois problemas, poderá ser comparado às ELMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação da ELM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse tipo de modelo é feita a escolha de uma matriz de pesos Z aleatória que, através do aumento de dimensão no espaço da camada intermediária, busca garantir a separação linear nesse espaço. Resumidamente, o intuito da ELM é que o número de funções $g_i (\\textbf{x}, \\textbf{z}_i)$ seja suficientemente grande para garantir a separabilidade no espaço da camada intermediária. Após isso, uma solução direta de erro mínimo pode ser obtida.\n",
    "\n",
    "Como descrito em [2], a ELM possui um método de aprendizado simples, descrito a seguir.\n",
    "\n",
    "Dado um \\textit{dataset} de treinamento com N amostras $\\{(\\textbf{x}_i, \\textbf{y}_i) \\backslash \\textbf{x}_i \\in \\textbf{R}^n, \\textbf{y}_i \\in \\textbf{R}^m, i = 1,...,N\\} $ , uma função de ativação $g(x)$ e um número de neurônios da camada escondida Ñ:\n",
    "\n",
    "- Gerar uma matriz de pesos de entrada Z tal que $ Z \\in R^{n x Ñ} $.\n",
    "\n",
    "- Calcular a matriz de mapeamento H (saída da camada escondida), tal que $ H = g(\\textbf{XZ}) $.\n",
    "\n",
    "- Calcular os pesos da camada de saída, $ \\textbf{W} = \\textbf{H}^+\\textbf{Y} $, sendo $\\textbf{H}^+$ a pseudo-inversa de $\\textbf{H}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class ELM:\n",
    "         \n",
    "    def __init__(self, n_neurons):\n",
    "        self.n_neurons = n_neurons\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Adding polarization term \n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        n = X_new.shape[1]\n",
    "        self.Z = np.array([random.uniform(-0.5, 0.5) for i in range(n*self.n_neurons)]).reshape(n, self.n_neurons)\n",
    "        H = np.tanh(np.dot(X_new, self.Z))\n",
    "        H_new = np.ones((H.shape[0], H.shape[1]+1))\n",
    "        H_new[:,1:] = H\n",
    "        self.w = np.dot(np.linalg.pinv(H_new), y)           \n",
    "        return self.w, H, self.Z\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X_new = np.ones((X.shape[0], X.shape[1]+1))\n",
    "        X_new[:,1:] = X\n",
    "        H = np.tanh(np.dot(X_new, self.Z))\n",
    "        H_new = np.ones((H.shape[0], H.shape[1]+1))\n",
    "        H_new[:,1:] = H\n",
    "        y_predicted = np.sign(np.dot(H_new, self.w))\n",
    "        y_predicted[y_predicted==0]=1\n",
    "        return y_predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação do Perceptron Simples\n",
    "\n",
    "O Perceptron de uma única camada é utilizado para dividir duas classes linearmente separáveis.\n",
    "O funcionamento do Perceptron de camada única é muito simples, as entradas (Xi) representam as informações do processo que desejamos mapear, sendo que cada uma das entradas terá um peso ponderado (Wi) que representa a importância de cada entrada em relação ao valor de saída desejado (y). O resultado da somatória das entradas ponderadas será somado ao limiar de ativação (θ) e então repassado como argumento da função de ativação g(.), a qual terá como resultado a saída desejada. Normalmente a função de ativação costuma ser do tipo função degrau ou degrau bipolar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, learning_rate=0.1, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.activation_func = self._unit_step_func\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        # init parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        y_ = np.array([1 if i > 0 else 0 for i in y])\n",
    "        for _ in range(self.n_iters):        \n",
    "            for idx, x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                y_predicted = self.activation_func(linear_output)               \n",
    "                # Perceptron update rule\n",
    "                update = self.lr * (y_[idx] - y_predicted)\n",
    "                self.weights += update * x_i\n",
    "                self.bias += update\n",
    "        return (np.concatenate(([self.bias], self.weights)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.activation_func(linear_output)\n",
    "        return y_predicted\n",
    "\n",
    "    def _unit_step_func(self, x):\n",
    "        return np.where(x>=0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para Captação de Resultados da ELM e Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultsELM(X, y, max_iterations, p):\n",
    "    train_accuracy_ELM = np.zeros(max_iterations)\n",
    "    test_accuracy_ELM = np.zeros(max_iterations)  \n",
    "    for i in range(0, max_iterations):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        # Normalizing data:\n",
    "        normalizer = preprocessing.Normalizer()\n",
    "        X_train = normalizer.fit_transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "      \n",
    "        # ELM\n",
    "        clf = ELM(p)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_hat_train=clf.predict(X_train)\n",
    "        y_hat=clf.predict(X_test)\n",
    "        train_accuracy_ELM[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy_ELM[i] = accuracy_score(y_test, y_hat)\n",
    "     \n",
    "    print(f\"********* Results ELM (p = {p})**************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy_ELM.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy_ELM.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy_ELM.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy_ELM.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_perceptron(X, y, max_iterations):\n",
    "    train_accuracy = np.zeros(max_iterations)\n",
    "    test_accuracy = np.zeros(max_iterations)  \n",
    "    for i in range(0, max_iterations):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        # Normalizing data:\n",
    "        normalizer = preprocessing.Normalizer()\n",
    "        X_train = normalizer.fit_transform(X_train)\n",
    "        X_test = normalizer.transform(X_test)\n",
    "      \n",
    "        # Perceptron\n",
    "        clf = Perceptron(learning_rate=0.1, n_iters=5000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_hat_train=clf.predict(X_train)\n",
    "        y_hat=clf.predict(X_test)\n",
    "        train_accuracy[i] = accuracy_score(y_train, y_hat_train)   \n",
    "        test_accuracy[i] = accuracy_score(y_test, y_hat)\n",
    "     \n",
    "    print(f\"********* Results Percetron **************\")\n",
    "    print(\"Acc train: \" + '{:.4f}'.format(train_accuracy.mean())+ \"+/-\" + '{:.4f}'.format(train_accuracy.std()))\n",
    "    print(\"Acc test: \" + '{:.4f}'.format(test_accuracy.mean()) + \"+/-\" + '{:.4f}'.format(test_accuracy.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação da ELM na base Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Results ELM (p = 5)**************\n",
      "Acc train: 0.9292+/-0.0079\n",
      "Acc test: 0.9175+/-0.0252\n",
      "********* Results ELM (p = 10)**************\n",
      "Acc train: 0.9444+/-0.0098\n",
      "Acc test: 0.9482+/-0.0182\n",
      "********* Results ELM (p = 30)**************\n",
      "Acc train: 0.9730+/-0.0060\n",
      "Acc test: 0.9596+/-0.0148\n",
      "********* Results ELM (p = 50)**************\n",
      "Acc train: 0.9771+/-0.0024\n",
      "Acc test: 0.9526+/-0.0131\n",
      "********* Results ELM (p = 100)**************\n",
      "Acc train: 0.9829+/-0.0043\n",
      "Acc test: 0.9430+/-0.0272\n",
      "********* Results ELM (p = 200)**************\n",
      "Acc train: 0.9978+/-0.0020\n",
      "Acc test: 0.9246+/-0.0261\n",
      "********* Results ELM (p = 300)**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.8728+/-0.0272\n"
     ]
    }
   ],
   "source": [
    "wdbc_dataset = pd.read_csv('data/WDBC/wdbc.data', names=list(range(0,32)))\n",
    "# convert to array\n",
    "y = wdbc_dataset[1].to_numpy()\n",
    "X = wdbc_dataset.drop([0, 1],axis='columns').to_numpy()\n",
    "y[np.where(y=='B')] = 1\n",
    "y[np.where(y=='M')] = -1\n",
    "y = np.array(y.tolist())\n",
    "for p in [5, 10, 30, 50, 100, 200, 300]:\n",
    "    resultsELM(X, y, 10, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação do Perceptron na base Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Results Percetron **************\n",
      "Acc train: 0.9013+/-0.0303\n",
      "Acc test: 0.8904+/-0.0578\n"
     ]
    }
   ],
   "source": [
    "y[y==-1] = 0\n",
    "results_perceptron(X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação da ELM na base Statlog (Heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Results ELM (p = 5)**************\n",
      "Acc train: 0.7690+/-0.0532\n",
      "Acc test: 0.7593+/-0.0468\n",
      "********* Results ELM (p = 10)**************\n",
      "Acc train: 0.8417+/-0.0299\n",
      "Acc test: 0.8019+/-0.0550\n",
      "********* Results ELM (p = 30)**************\n",
      "Acc train: 0.8690+/-0.0110\n",
      "Acc test: 0.8370+/-0.0412\n",
      "********* Results ELM (p = 50)**************\n",
      "Acc train: 0.8870+/-0.0148\n",
      "Acc test: 0.8204+/-0.0483\n",
      "********* Results ELM (p = 100)**************\n",
      "Acc train: 0.9356+/-0.0106\n",
      "Acc test: 0.7556+/-0.0590\n",
      "********* Results ELM (p = 200)**************\n",
      "Acc train: 0.9995+/-0.0014\n",
      "Acc test: 0.5519+/-0.0651\n",
      "********* Results ELM (p = 300)**************\n",
      "Acc train: 1.0000+/-0.0000\n",
      "Acc test: 0.6167+/-0.0609\n"
     ]
    }
   ],
   "source": [
    "statlog_dataset = pd.read_csv('data/statlog/heart.dat', sep=\"\\s+\", engine='python', header=None)\n",
    "X = statlog_dataset.drop((13), 1).to_numpy()\n",
    "y = statlog_dataset.iloc[:, 13].to_numpy()\n",
    "y[y==2] = -1\n",
    "for p in [5, 10, 30, 50, 100, 200, 300]:\n",
    "    resultsELM(X, y, 10, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação do Perceptron na base Statlog (Heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Results Percetron **************\n",
      "Acc train: 0.8037+/-0.0705\n",
      "Acc test: 0.8296+/-0.0467\n"
     ]
    }
   ],
   "source": [
    "y[y==-1] = 0\n",
    "results_perceptron(X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perguntas:\n",
    "\n",
    "1) Com quantos neurônios (aproximadamente) a acurácia de teste aparenta ser máxima?\n",
    "\n",
    "A acurácia máxima de teste para a base de dados *Breast Cancer* foi atingida para a ELM com 50 neurônios na camada escondida (0.9632+/-0.0110). Já para a base de dados *Statlog (Heart)*, essa acurácia máxima foi de 0.8037+/-0.0333, e foi obtida para as redes com 10 e 30 neurônios na camada escondida.\n",
    "\n",
    "2) O que acontece com os valores de acurácia de treinamento e teste conforme aumentamos progressivamente o número de neurônios (por exemplo, para 5, 10, 30, 50, 100, 300 neurônios)?\n",
    "\n",
    "Percebeu-se que a acurácia de treinamento aumenta progressivamente de acordo com o aumento do número de neurônios. Contudo esse comportamente não é o mesmo no caso da acurácia de teste. Essa aumenta até certo momento de acordo com o número de neurônios, porém a partir de um certo ponto percebe-se que o modelo sofre *overfitting*, ocasionando uma menor acurácia de teste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussão Perceptron x ELM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pôde-se perceber que a ELM obteve resultados superiores ao Perceptron Simples. A principal causa disso se deve ao fato de as bases de dados não serem linearmente separáveis. Dessa forma um modelo como a ELM (capaz de lidar com bases não linearmente separáveis) tende a obter resultados superiores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "[1] D. Dua and C. Graff, “UCI machine learning repository,” 2017. [Online]. Available: http://archive.ics.uci.edu/ml\n",
    "\n",
    "[2] G.-B. Huang, Q.-Y. Zhu, and C.-K. Siew, “Extreme learning machine: theory and applications,” Neurocomputing, vol. 70, no. 1-3, pp. 489–501, 2006."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
